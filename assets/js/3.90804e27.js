(window.webpackJsonp=window.webpackJsonp||[]).push([[3],{362:function(t,s,a){t.exports=a.p+"assets/img/template_convolved.667e533f.png"},363:function(t,s,a){t.exports=a.p+"assets/img/deneb_spec_convolved.55bfaec6.png"},364:function(t,s,a){t.exports=a.p+"assets/img/degrade_lamost.ba23401c.png"},375:function(t,s,a){"use strict";a.r(s);var n=a(25),p=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"降低分辨率"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#降低分辨率"}},[t._v("#")]),t._v(" 降低分辨率")]),t._v(" "),n("h2",{attrs:{id:"简介"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),n("p",[t._v("『降低分辨率』多用于不同分辨率光谱的比较上，主要是将较高的分辨率光谱（如理论合成光谱）降低至较低的观测光谱分辨率（如 SDSS, LAMOST）。")]),t._v(" "),n("p",[t._v('降低分辨率在文章的数据处理部分中多被描述为 "degrade the spectral resolution" 或者 "convolve the spectra using Gaussian Kernel"。')]),t._v(" "),n("h2",{attrs:{id:"方法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法"}},[t._v("#")]),t._v(" 方法")]),t._v(" "),n("p",[t._v("该步骤实际上就是用一个一维高斯滤波器对一维光谱进行卷积操作，起到模糊平滑的作用。")]),t._v(" "),n("div",{staticClass:"custom-block warning"},[n("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),n("p",[t._v("笔者在最初操作中，将『降低分辨率』与『下采样』的概念混淆。在与导师的沟通交流中，也了解到有学生在论文中犯过同样的错误。")])]),t._v(" "),n("p",[t._v("『下采样』是对一个序列间隔几个样值采样一次，e.g. "),n("code",[t._v("[1, 1, 2, 2, 3, 3]")]),t._v(" 如果间隔 step = 2 进行采样，则新序列为 "),n("code",[t._v("[1, 2, 3]")]),t._v("。")]),t._v(" "),n("h2",{attrs:{id:"最佳实践"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#最佳实践"}},[t._v("#")]),t._v(" 最佳实践")]),t._v(" "),n("p",[t._v("在实际的光谱处理中，我们需要『具体问题具体分析』，针对不同的光谱仪器特征，或是科学目的、实验精度等，对光谱进行特定的降低分辨率操作。")]),t._v(" "),n("p",[t._v("下面以 4 个例子进行讲解，实验代码均在 Python 3 下运行。")]),t._v(" "),n("p",[n("strong",[t._v("笔者对第 ③ 个 LAMOST 的例子进行了详细的代码注解。")])]),t._v(" "),n("h3",{attrs:{id:"_1-基本操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-基本操作"}},[t._v("#")]),t._v(" ① 基本操作")]),t._v(" "),n("blockquote",[n("p",[t._v("详情请参考 "),n("a",{attrs:{href:"https://lotharschanne.wordpress.com/convolution-of-1d-spectra-with-gaussian-functions/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Convolution of 1d-spectra with Gaussian functions"),n("OutboundLink")],1)])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" astropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("convolution "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Gaussian1DKernel\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" astropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("convolution "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" convolve\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" astropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),t._v("\n\nspectrum_name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Path and name of the file: '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nstd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("'Standard deviation "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the convolution "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" multiples of the\\\n increment"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" '"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Spektrum einlesen")]),t._v("\nspectrum "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spectrum_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" guess"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   Convolve using astropy.convolution")]),t._v("\nkernel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Gaussian1DKernel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("std"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconvoluted "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" convolve"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spectrum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'FLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kernel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normalize_kernel"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      boundary"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extend'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nname "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spectrum_name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'_convolved.dat'")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Graphics")]),t._v("\nfig "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" figsize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("suptitle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Spectrum '")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("spectrum_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spectrum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" spectrum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'FLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Wavelength in Angstrom'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'relative Flux'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spectrum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" convoluted"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Wavelength in Angstrom'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'relative Flux'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# saving graphics")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savefig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.png'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savefig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.pdf'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Saving of convolved")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("spectrum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" convoluted"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" overwrite"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            names"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'FLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tab'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:a(362),alt:""}})]),t._v(" "),n("h3",{attrs:{id:"_2-处理-pollux-模型光谱"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-处理-pollux-模型光谱"}},[t._v("#")]),t._v(" ② 处理 POLLUX 模型光谱")]),t._v(" "),n("blockquote",[n("p",[t._v("详情请参考 "),n("a",{attrs:{href:"https://lotharschanne.wordpress.com/processing-of-pollux-model-spectra/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Processing POLLUX model spectra"),n("OutboundLink")],1)]),t._v(" "),n("p",[t._v("POLLUX 是一个高分辨率的理论合成光谱库")])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" astropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("convolution "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Gaussian1DKernel\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" astropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("convolution "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" convolve\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" astropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'path and name of the file: '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlambda_min "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Input of the start wavelength in the spectrum: '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndeltalambda "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Input of the step in the spectrum: '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("'Standard deviation "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the convolution "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" multiples of the\\\n increment"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" '"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ntable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_fwf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" names"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'AFLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NFLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nwl_li "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Begin of Wavelength range: '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwl_re "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'End of Wavelength range: '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nind_li "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wl_li"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("lambda_min"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" deltalambda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nind_re "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wl_re"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("lambda_min"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" deltalambda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbereich "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ind_li"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("ind_re"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   Convolve using astropy.convolution")]),t._v("\nkernel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Gaussian1DKernel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("std"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncon "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bereich"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NFLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconvoluted "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" convolve"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kernel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normalize_kernel"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      boundary"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extend'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Graphics")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("style"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("use"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'seaborn-whitegrid'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_size_inches"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Wavelength [Angstrom]'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("suptitle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Spectrum '")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("grid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NFLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bereich"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bereich"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NFLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bereich"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" convoluted"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savefig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.png'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savefig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.pdf'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save convoluted spectrum, NFLUX now as FLUX")]),t._v("\nconvol_file "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bereich"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" convoluted"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                           columns"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NFLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nname "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rstrip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.spec'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'_convolved.dat'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("bereich"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" convoluted"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" overwrite"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            names"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'WAVE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'FLUX'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tab'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:a(363),alt:""}})]),t._v(" "),n("h3",{attrs:{id:"_3-降至-lamost-光谱的低分辨率"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-降至-lamost-光谱的低分辨率"}},[t._v("#")]),t._v(" ③ 降至 LAMOST 光谱的低分辨率")]),t._v(" "),n("blockquote",[n("p",[t._v("实验中用到的分辨率为 50,000 的光谱 ​"),n("a",{attrs:{href:"https://gitee.com/iScottMark/Astro/raw/master/docs/spectroscopy/spectra_process/ap00t5777g44377k1odfnew_50000.spec",target:"_blank",rel:"noopener noreferrer"}},[t._v("📗 下载链接"),n("OutboundLink")],1)])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scipy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("signal\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scipy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ndimage "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" gaussian_filter1d\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scipy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" interpolate\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("conv")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("origin_flux"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old_resolution"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" new_resolution"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" step"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('""" degrade spectral resolution in LAMOST scale\n    :param origin_flux: the original flux of high spectral resolution\n    :param old_resolution: high resolution\n    :param new_resolution: low resolution\n    :param step: the step of original spectra wavelength\n    :return: the degraded flux of low resolution\n    """')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5000 angstrom is the approximate central wavelength of LAMOST")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2.355 is the constant of the transformation from FWHM (i.e. delta lambda) to sigma")]),t._v("\n    sigma "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" new_resolution"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" old_resolution"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.355")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" step"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use gaussian kernel to degrade the spectra")]),t._v("\n    degraded_flux "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" gaussian_filter1d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("origin_flux"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sigma"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" degraded_flux\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'__main__'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 读取原始光谱文件")]),t._v("\n    data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loadtxt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ap00t5777g44377k1odfnew_50000.spec'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    wave_01 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 原始波长的步长间隔为 0.1 angstrom")]),t._v("\n    flux_01 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对光谱进行插值，分别将流量插值到波长的步长间隔为 0.01 和 0.005")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 同时，为了方便展示，只截取 [4800, 6800] 这一段波长")]),t._v("\n    wave_001 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4800")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6800")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    flux_001 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" interpolate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interp1d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flux_01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_001"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    wave_0005 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4800")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6799.99")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.005")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    flux_0005 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" interpolate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interp1d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flux_01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_0005"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分别对步长为 0.01 和 0.005 的流量降低分辨率")]),t._v("\n    flux_001_degrade "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("origin_flux"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("flux_001"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old_resolution"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            new_resolution"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7500")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" step"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    flux_0005_degrade "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("origin_flux"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("flux_0005"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old_resolution"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             new_resolution"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7500")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" step"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.005")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 画图")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flux_01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b-'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'step01'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# + 40 偏移，否则步长为 0.01 的绿线会被步长为 0.005 的红线完全覆盖，看不出来")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_001 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flux_001_degrade"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'g-'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'step001'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave_0005"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flux_0005_degrade"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r--'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'step0005'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" alpha"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:a(364),alt:""}})]),t._v(" "),n("h3",{attrs:{id:"_4-降低不等间隔波长步长的光谱分辨率"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-降低不等间隔波长步长的光谱分辨率"}},[t._v("#")]),t._v(" ④ 降低不等间隔波长步长的光谱分辨率")]),t._v(" "),n("blockquote",[n("p",[t._v("详情请参考 "),n("a",{attrs:{href:"https://github.com/jason-neal/convolve_spectrum",target:"_blank",rel:"noopener noreferrer"}},[t._v("convolve_spectra"),n("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=p.exports}}]);